# DATE: 06/28

## 계획:
 백엔드 처리 => 리엑트 => 프로젝트 순  
 프로젝트 기간 8주  

## AWS 등은 배포도 염두에 두고 해보자 허나 수업 내용엔 포함되어 있지 않으니 셀프로 공부해야한다.  

## 리엑트에선 함수형 컴포넌트만 사용하자.  
커스텀 훅스, useReducer등의 사용  

## 오늘 토픽: 크롤링 jsoup + selenium
파일 복사:
  1. 인풋 스트림으로 읽는다
  2. 아웃풋 스트림으로 쓴다
TCP socket의 원리:
  * 종이컵 전화기와 비슷하다.
  * inputStream && outputStream

크롤링을 이용한 파일 다운로드:
  1. 대상 URL 결정 => get방식으로
  2. 브라우저에서 확인
  3. URL 객체 생성
  4. getInputStream() 혹은 openStream등을 이용해 inputStream을 가져온다
  5. outputStream을 구한다  (FileOutputStream 등을 이용)
  6. 읽고 쓴디 => Files.copy()  

네이버 웹툰이 크롤링을 통한 다운로드를 막는 방법:  
  * 크롤링을 이용한 접근이 브라우저가 아니라는 것을 감지한후, 브라우저가 아니라면 403에러를 보내 예외를 발생시킨다.  
  * * 파라미터, 바디 데이터를 요구하여 인증/검증한다. 없거나 정확하지 않을시 에러 처리   
이걸 뚫어내는 방법은?  
  * 크롤링시 헤더 정보를 수정하여 크롤링하는 자신을 브라우저로 인식하게 바꾸는 방법.  
  * 파라미터, 바디 데이터를 전달하여 인증/검증을 통과하는 방법.  

### 크롤링:  
1. 대상 URL을 찾는다  
2. HTTP Parsing 한다.  
  * 상세 주소  
  * URL연결.  
  * 이미지 태그를 찾아야한다  
  * 이후 그 이미지 태그의 src를 in/outputStream을 이용해 저장    

이때 정상적인 브라우저의 접근 등을 파악하려 할수도 있다:  
* user-agent를 활용(네이버 웹툰)   
* 브라우저에서 보이지 않는 어떤 값     
* 특정한 파라미터를 쓰는 경우 (CU가 이런 경우. CSRF 토큰을 이용해 막는다 ==> 가장 대표적인 방법. 뚫을 수 있는 방법도 있다.)   

### CSRF란? 
요청을 위조/변조하여 서버를 공격하는 방법. 

## Selenium:
간단하게는 프로그램을 통해서 제어를 해 필요한 정보를 가져오는 것을 도와주는 라이브러리.    

사용법:  
1. 두개의 jar파일이 필요. ==> 셀레니움 자바 클라이언트 && 셀레니움 이걸 하기 위해선 Chrome Driver가 필요  
2. 이후부터는 그냥 셀레니움 문법따라 쓰면된다.  

## DB를 사용하는 법:
1. 클라우드를 사용하는 법 ==> AWS, ORACLE cloud
2. Docker를 이용하는 방법
  * 도커란?
  * ==> 도커의 장점: 로컬에서 작업 후, 그대로 그 데이터를 실제 서버에 올리거나 할 수 있다.  
3. 개인 PC에 세팅해서 사용.  
  * 2가지 방법:  
  * 원격에서 접속 가능하게  
  * 로컬에서만 ==> 로컬에서만 쓰기에 이 데이터가 적용되기가 힘들다.  



